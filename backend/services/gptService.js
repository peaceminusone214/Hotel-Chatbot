const { OpenAI } = require("openai");
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

exports.getGPTReply = async (hotel, rooms, message, contextSummary = "") => {
  const roomText = rooms.map(r =>
    `- ${r.name}: ${r.capacity} ng∆∞·ªùi, ${r.view}, ${r.price}ƒë, ti·ªán nghi: ${r.amenities.join(', ')}`
  ).join('\n');

  const systemPrompt = hotel.prompt || `B·∫°n l√† l·ªÖ t√¢n kh√°ch s·∫°n ${hotel.name} t·∫°i ƒë·ªãa ch·ªâ ${hotel.address}. Lu√¥n t∆∞ v·∫•n ng·∫Øn g·ªçn, th√¢n thi·ªán v√† g·ª£i √Ω ph√≤ng ph√π h·ª£p v·ªõi nhu c·∫ßu kh√°ch.`;

  const messages = [
    { role: "system", content: systemPrompt },
    { role: "system", content: `Danh s√°ch ph√≤ng:\n${roomText}` },
  ];

  if (contextSummary?.trim()) {
    messages.push({
      role: "system",
      content: `T√≥m t·∫Øt h·ªôi tho·∫°i tr∆∞·ªõc ƒë√≥ (ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh): ${contextSummary}`
    });
  }

  messages.push({ role: "user", content: message });

  const chatCompletion = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages,
    max_tokens: 300
  });

  return chatCompletion.choices[0].message.content.trim();
};

// üîÅ T√ìM T·∫ÆT NG·ªÆ C·∫¢NH
exports.summarize = async (prevSummary, newMessage, newReply) => {
  const messages = [
    {
      role: "system",
      content: "B·∫°n l√† AI t√≥m t·∫Øt h·ªôi tho·∫°i gi·ªØa kh√°ch h√†ng v√† chatbot kh√°ch s·∫°n."
    },
    {
      role: "user",
      content: `
T√≥m t·∫Øt tr∆∞·ªõc ƒë√≥: "${prevSummary || "(ch∆∞a c√≥)"}"
Kh√°ch: "${newMessage}"
Chatbot: "${newReply}"

T√≥m t·∫Øt to√†n b·ªô h·ªôi tho·∫°i ƒë·∫øn hi·ªán t·∫°i (ng·∫Øn g·ªçn, ch·ªâ n·ªôi dung ch√≠nh):`
    }
  ];

  const summaryResult = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages,
    max_tokens: 150,
  });

  return summaryResult.choices[0].message.content.trim();
};
